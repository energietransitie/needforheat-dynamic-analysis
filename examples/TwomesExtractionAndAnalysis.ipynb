{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twomes interactive inverse grey-box analysis pipeline\n",
    "\n",
    "This Jupyter Labs notebook can be used to interactively test the Twomes inverse grey-box analysis pipeline, accessing data from a Twomes database (see also [more information how to setup a Twomes server](https://github.com/energietransitie/twomes-backoffice-configuration#jupyterlab)).\n",
    "Don't forget to install the requirements listed in [requirements.txt](../requirements.txt) first!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the stage\n",
    "\n",
    "First several imports and variables need to be defined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and generic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import math\n",
    "import pylab as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# usually, two decimals suffice for displaying DataFrames (NB internally, precision may be higher)\n",
    "pd.options.display.precision = 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('../data/')\n",
    "sys.path.append('../view/')\n",
    "sys.path.append('../analysis/')\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%matplotlib widget\n",
    "from plotter import Plot\n",
    "from filewriter import ExcelWriter as ex\n",
    "\n",
    "from extractor import WeatherExtractor, Extractor, Period\n",
    "\n",
    "from inversegreyboxmodel import Learner\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger('Twomes data extraction')\n",
    "logger.setLevel(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis settings\n",
    "\n",
    "- which `learn_duration` should be used for the analysis\n",
    "- and various other global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_std_outliers = 3.0 # default for the multiplier of the the standard deviation; further out than this times the std, outliers are removed during preprocessing\n",
    "up_intv = '5min' # the default upsampling interval that is used before interpolation is done\n",
    "gap_n_intv = 11 # the default maximum number of consecutive NaNs to fill(one for each upsampling interval), i.e. valid measurement values (11+1)* 5 min = 1 hour apart apart will be bridget by interpolation, but not more\n",
    "sampling_interval = '15min' # the default interval on which interpolation will be done during preprocessing\n",
    "learn_duration_d = 7\n",
    "required_columns_for_sanity = ['temp_out__degC', 'wind__m_s_1','ghi__W_m_2', 'temp_in__degC', 'g_use__W', 'e_use__W', 'e_ret__W']\n",
    "sanity_threshold_timedelta = timedelta(hours=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining which homes, which period \n",
    "\n",
    "- which `homes` should be analysed\n",
    "- what the location and timezone is of those homes (currently, we only support one location and timezone for a batch of homes) \n",
    "\n",
    "- from which `start_day` to which `end_day'  the analysis should run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location: center of Assendorp neighbourhood in Zwolle\n",
    "lat, lon = 52.50655, 6.09961\n",
    "\n",
    "\n",
    "#timezone: \n",
    "timezone_database = 'UTC'\n",
    "timezone_homes = 'Europe/Amsterdam'\n",
    "\n",
    "\n",
    "# Below, the maximum period for data collection\n",
    "first_day = pytz.timezone(timezone_homes).localize(datetime(2021, 10, 25))\n",
    "last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 5, 8))\n",
    "\n",
    "# Alternatively, you may want to test things only on a three week periode. This is a period with suitable weather and lots of homes with measurements.\n",
    "# first_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 3))\n",
    "# last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 31))\n",
    "\n",
    "# The full set of homes\n",
    "homes = [803422, 805164, 809743, 811308, 815925, 817341, 822479, 829947, 830088, 831062, 839440, 845966, 845997, 846697, 857477, 864296, 873985, 879481, 881611, 886307, 895671, 897349, 899510]\n",
    "\n",
    "# # A subset of homes\n",
    "# homes = [803422, 805164, 809743]\n",
    "\n",
    "# single home for virtual homes\n",
    "# homes = [886307]\n",
    "\n",
    "# single home for gap assessment\n",
    "# homes = [803422]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and geospatial interpolation of Dutch weather data\n",
    "\n",
    "Using an external library installaed via [requirements.txt](../requirements.txt), load and geospatially interpolate Dutch weather data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "%autoreload 2\n",
    "\n",
    "# get geospatially interpolated weather from KNMI\n",
    "# for Twomes, the Weather for all all homes studies can be approached by a single location\n",
    "# get the dataframe only once for all homes to save time\n",
    "tz_knmi='Europe/Amsterdam'\n",
    "\n",
    "df_weather = WeatherExtractor.get_interpolated_weather_nl(first_day, last_day, lat, lon, tz_knmi, timezone_homes, sampling_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check descriptive statisctics about the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting time-interpolated home data from the Twomes database and combine with weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "df_data_homes = Extractor.get_preprocessed_homes_data(homes, first_day, last_day, timezone_database, timezone_homes,\n",
    "                                                      up_intv, gap_n_intv, sampling_interval, \n",
    "                                                      df_weather)\n",
    "logger.setLevel(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional block to get interpolated data from virtual homes in CSV files and combine with weather data already obtained\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "# %autoreload 2\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "# homes = [\n",
    "#     60200, \n",
    "#     120100, \n",
    "#     150080, \n",
    "#     150100, \n",
    "#     200060, \n",
    "#     300040, \n",
    "#     400030, \n",
    "#     600020 \n",
    "# ]\n",
    "\n",
    "# # For virtual homes, only the following period is valid:\n",
    "# first_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 3))\n",
    "# last_day = pytz.timezone(timezone_homes).localize(datetime(2022, 1, 24))\n",
    "\n",
    "# df_data_homes = pd.DataFrame()\n",
    "# for home_id in homes:\n",
    "#     df_data_homes = pd.concat([df_data_homes, Extractor.get_virtual_home_data_csv(str('../data/virtualhome_P{0}.csv'.format(home_id)), timezone_homes)], axis=0)\n",
    "\n",
    "# logger.setLevel(logging.NOTSET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_homes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn parameters using inverse grey-box analysis\n",
    "\n",
    "Most of the heavy lifting is done by the `learn_home_parameters()` function, which again uses the [GEKKO Python](https://machinelearning.byu.edu/) dynamic optimization toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "%autoreload 2\n",
    "\n",
    "# Use one of the lines below to set the moving horizon duration used for analysis \n",
    "# learn_duration_d_analysis = 14\n",
    "learn_duration_d_analysis = learn_duration_d\n",
    "\n",
    "\n",
    "# learn the model parameters and write rerults an intermediate results to excel files\n",
    "df_results_model_parameters, df_results_tempsim = Learner.learn_home_parameters(df_data_homes, \n",
    "                                                         n_std_outliers, up_intv, gap_n_intv, sampling_interval, \n",
    "                                                         learn_duration_d_analysis, \n",
    "                                                         req_col = required_columns_for_sanity, sanity_threshold_timedelta = sanity_threshold_timedelta,\n",
    "                                                         hint_A_m2=None, ev_type=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Show the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show learned model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show table of all learned model parameters of all homes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_model_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results of all learned model parameters of all homes in one plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "Plot.learned_parameters_boxplot('Learned model parameters for homes', df_results_model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize results of all learned model parameters by week for each home multiple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "Plot.learned_parameters_plot(df_results_model_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show best fitting simulated temperatures and power flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_to_mathtext = property_types = {\n",
    "    'degC' : r'$Â°C$',\n",
    "    'W' : r'$W$',\n",
    "    'W_m_2' : r'$W\\cdotm^{-1}$'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show table of best fitting simulated temperatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_tempsim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show a plot with the best fitting simulated temperatures and power flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "Plot.dataframe_properties_plot(df_results_tempsim,units_to_mathtext)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
